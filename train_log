
==================================================
PREPARING TRAINING
==================================================
Indexing .pt files in /Users/yihein.chai/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Research/meg/cache/meg_windows_cache...
Loaded 3387 windows ready for training
  Storage format: PyTorch tensors (float16)
  Benefits: No parsing overhead + Perfect shuffling + Max GPU usage
Total training windows: 3387
Creating DataLoader with batch_size=64, 8 workers...
Total batches per epoch: 53

Initializing model...
Encoder moved to cpu
Loss function and optimizer initialized
==================================================

==================================================
STARTING TRAINING
==================================================
Training for 10 epochs


Epoch [1/10]
--------------------------------------------------
  Batch [0/53] Loss: nan
  Batch [10/53] Loss: nan
