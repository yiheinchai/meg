# AUTOGENERATED! DO NOT EDIT! File to edit: understand.ipynb.

# %% auto 0
__all__ = ['base_path', 'rest_path', 'noise_path', 'data_cc110033', 'data_cc110037', 'data_cc110045', 'datalist', 'aug_pipeline',
           'datasets', 'train_loader', 'encoder', 'criterion', 'optimiser', 'num_epochs', 'fig', 'ax', 'display_handle',
           'losses', 'batch_nums', 'all_embeddings', 'all_embeddings_list', 'age_labels_list', 'sex_labels_list',
           'individual_details_mapping', 'dim_reducer', 'embedding_2d', 'age_labels_numpy', 'sex_labels_numpy', 'plot1',
           'plot2', 'load_meg_data', 'NoiseInjection', 'StdGaussianNoise', 'ZScore', 'Encoder', 'NTXentLoss',
           'MEG_Dataset']

# %% understand.ipynb 0
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import json
from pathlib import Path
import mne
import warnings
import torch
import torchvision.transforms as transforms
import torch.nn as nn
from torch.utils.data.dataset import Dataset
from torch.utils.data import DataLoader, ConcatDataset
import torch.optim as optim
from tqdm.notebook import tqdm
from IPython.display import clear_output, display
import umap

warnings.filterwarnings('ignore')

# Set plotting style
sns.set_style('whitegrid')
plt.rcParams['figure.figsize'] = (12, 6)

# Define dataset paths
base_path = Path('/Users/yihein.chai/Library/CloudStorage/OneDrive-UniversityCollegeLondon/Research/meg/CamCAN/cc700')
rest_path = base_path / 'rest'
noise_path = base_path / 'noise'

print("Dataset paths configured successfully!")

# %% understand.ipynb 2
# Load real MEG data from CamCAN dataset
def load_meg_data(subject_id, base_path=rest_path):
    """
    Load and preprocess MEG data for a given subject.
    
    Parameters:
    -----------
    subject_id : str
        Subject ID (e.g., 'CC110033')
    base_path : Path
        Base path to the dataset
        
    Returns:
    --------
    data : ndarray
        Preprocessed MEG data of shape (n_channels, n_samples)
    """
    # Construct file path
    meg_file = base_path / f'sub-{subject_id}' / 'meg' / f'sub-{subject_id}_task-rest_meg.fif'
    
    if not meg_file.exists():
        raise FileNotFoundError(f"MEG file not found: {meg_file}")
    
    # Load MEG data using MNE
    raw = mne.io.read_raw_fif(meg_file, preload=True, verbose=False)
    
    # Keep only magnetometers for simplicity (102 channels)
    raw.pick_types(meg=True)
    
    # # Apply basic preprocessing
    # raw.filter(l_freq=1, h_freq=45, verbose=False)  # Band-pass filter
    # raw.notch_filter([50, 100], verbose=False)  # Remove line noise
    
    # Get data as numpy array
    data = raw.get_data()  # Shape: (n_channels, n_samples)
    
    return torch.from_numpy(data)


# %% understand.ipynb 6
# Load data from multiple subjects
data_cc110033 = load_meg_data('CC110033')
data_cc110037 = load_meg_data('CC110037')
data_cc110045 = load_meg_data('CC110045')

datalist = [data_cc110033, data_cc110037, data_cc110045]

# %% understand.ipynb 9
class NoiseInjection():
    def __init__(self):
        pass

    def __call__(self, timeseries):
        if isinstance(timeseries, np.ndarray):
            timeseries = torch.from_numpy(timeseries)

        std = timeseries.std()
        
        noise = torch.randn_like(timeseries) * std
        return timeseries + noise
    

class StdGaussianNoise():
    def __init__(self, *, std):
        self.std = std

    def __call__(self, timeseries):
        if isinstance(timeseries, np.ndarray):
            timeseries = torch.from_numpy(timeseries)
        return timeseries + (torch.randn_like(timeseries) * self.std)


class ZScore():
    def __init__(self):
        pass

    def __call__(self, timeseries: torch.Tensor):
        mean = timeseries.mean(dim=-1, keepdim=True) # (batch, 306, ..time..) avg across time
        std = timeseries.std(dim=-1, keepdim=True)
        return (timeseries - mean) / std

# %% understand.ipynb 10
class Encoder(nn.Module):
    def __init__(self):
        super().__init__()

        self.conv1 = nn.Conv1d(in_channels=306, out_channels=64, kernel_size=3, padding=1) # batch, 64, window_size
        self.relu = nn.ReLU()
        self.avg_pool = nn.AdaptiveAvgPool1d(output_size=1) # batch, 64

        self.fc = nn.Linear(64, 128) # batch, 128

    def forward(self, x: torch.Tensor):
        x = x.float()
        x = self.conv1(x)
        x = self.relu(x)
        x = self.avg_pool(x)

        x = x.squeeze(-1)

        x = self.fc(x)
        # x = self.relu(x) # do not collapse the embedding space
        
        return x

# class Projection(nn.Module):
#     def __init__(self):
#         super().__init__()
#         self.fc = nn.Linear(64, 128)
#         self.relu = nn.ReLU()

#     def forward(self, x):
#         x = self.fc(x)
#         x = self.relu(x)

#         return x
    
# class Model()


# %% understand.ipynb 11
class NTXentLoss(nn.Module):
    def __init__(self, temperature=0.5):
        super().__init__()
        self.temperature = temperature

    def __call__(self, z1: torch.Tensor, z2: torch.Tensor):
        batch_size = z1.shape[0]

        z = torch.cat([z1, z2]) # 64 x 128 -> 128 x 128
        z = nn.functional.normalize(z)
        sim_matrix = (z @ z.T) / self.temperature

        # masking 
        sim_matrix = torch.masked_fill(sim_matrix, torch.eye(sim_matrix.shape[0]).bool(), -torch.inf)

        y = torch.Tensor([batch_size + i for i in range(batch_size)] + [i for i in range(batch_size)]).long()

        loss = nn.functional.cross_entropy(sim_matrix, y)

        return loss

# %% understand.ipynb 12
class MEG_Dataset(Dataset):
    def __init__(self, data, window_size=2000, transforms=None, stride=500):
        super().__init__()

        if transforms is None:
            raise TypeError("Transforms must be filled")
        
        self.window_size = window_size
        self.data = data
        self.transforms = transforms

        total_length = self.data.shape[-1]
        last_index = total_length - self.window_size
        self.stride = stride
        self.indices = [i for i in range(0, last_index, self.stride) if i <= last_index]

    def __len__(self):
        return len(self.indices)

    def __getitem__(self, index):
        start_index = self.indices[index]
        segment = self.data[:, start_index: start_index + self.window_size]
        view_1 = self.transforms(segment)
        view_2 = self.transforms(segment)

        return view_1, view_2

# %% understand.ipynb 14
aug_pipeline = transforms.Compose([ZScore(), StdGaussianNoise(std=0.1)])
datasets = [MEG_Dataset(data, window_size=2000, transforms=aug_pipeline) for data in datalist]
train_loader = DataLoader(ConcatDataset(datasets), batch_size=64, shuffle=True)

encoder = Encoder()
criterion = NTXentLoss(temperature=0.5)
optimiser = optim.Adam(encoder.parameters(), lr=1e-3)

# %% understand.ipynb 15
encoder.train()

num_epochs = 50

fig, ax = plt.subplots(figsize=(10, 6))
display_handle = display(fig, display_id=True)
losses = []
batch_nums = []

for epoch in tqdm(range(num_epochs), desc='Epochs'):
    epoch_loss = 0.0
    for batch_idx, (x1, x2) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}', leave=False)):
        z1 = encoder(x1)
        z2 = encoder(x2)

        loss = criterion(z1, z2)
        optimiser.zero_grad()
        loss.backward()
        optimiser.step()

        epoch_loss += loss.item()

        # Track metrics for live plot
        losses.append(loss.item())
        batch_nums.append(epoch * len(train_loader) + batch_idx)

        print(losses[-1])

        if batch_idx % 5 == 0 or batch_idx == len(train_loader) - 1:
            ax.clear()
            ax.plot(batch_nums, losses)
            ax.set_xlabel('Batch')
            ax.set_ylabel('Loss')
            ax.set_title('Training Loss per Batch')
            ax.grid(True)
            display_handle.update(fig)

    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss/len(train_loader):.4f}')

display_handle.update(fig)

# %% understand.ipynb 16
torch.save({"model_state_dict": encoder.state_dict(), "optimizer_state_dict": optimiser.state_dict()}, 'checkpoint.pth')

# %% understand.ipynb 17
encoder = Encoder()
encoder.load_state_dict(torch.load("checkpoint.pth", map_location=torch.device('cpu'))['model_state_dict'])

# %% understand.ipynb 18
encoder.eval()

all_embeddings = {}

with torch.no_grad():
    for i, data in enumerate(datalist):
        individual_embeddings = []
        infer_dataloader = DataLoader(MEG_Dataset(data, window_size=2000, transforms=transforms.Compose([ZScore()])), batch_size=256, shuffle=False)

        for x1, x2 in infer_dataloader:
            z1 = encoder(x1)
            individual_embeddings.append(z1)
        
        all_embeddings[i] = torch.cat(individual_embeddings, dim=0)




# %% understand.ipynb 19
all_embeddings_list = []
age_labels_list = []
sex_labels_list = []
individual_details_mapping = {
    0: {"age": 24.7, "sex": 1},
    1: {"age": 18.9, "sex": 1},
    2: {"age": 24.6, "sex": 0}
}

for idx, emd in all_embeddings.items():
    age = individual_details_mapping[idx]["age"]
    sex = individual_details_mapping[idx]["sex"]

    num_windows = emd.shape[0]
    all_embeddings_list.append(emd)

    age_labels = np.full(num_windows, age)
    age_labels_list.append(age_labels)

    sex_labels = np.full(num_windows, sex)
    sex_labels_list.append(sex_labels)



dim_reducer = umap.UMAP(n_neighbors=30, min_dist=0.1, n_components=2, random_state=42)
embedding_2d = dim_reducer.fit_transform(torch.cat(all_embeddings_list).numpy())

# %% understand.ipynb 22
age_labels_numpy = np.concatenate(age_labels_list, axis=0)
sex_labels_numpy = np.concatenate(sex_labels_list, axis=0)

# --- Create a 1x2 figure ---
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))

# --- Plot 1: Colored by AGE ---
plot1 = ax1.scatter(
    embedding_2d[:, 0], 
    embedding_2d[:, 1],
    c=age_labels_numpy,    # Color by age
    cmap='jet',            # Continuous colormap
    s=0.5,
    alpha=0.3
)
ax1.set_title('UMAP Projection Colored by Age')
ax1.set_xlabel('UMAP Dimension 1')
ax1.set_ylabel('UMAP Dimension 2')
fig.colorbar(plot1, ax=ax1, label='Participant Age')

# --- Plot 2: Colored by SEX ---
# (Assuming sex=0 and sex=1)
plot2 = ax2.scatter(
    embedding_2d[:, 0], 
    embedding_2d[:, 1],
    c=sex_labels_numpy,    # Color by sex
    cmap='coolwarm',       # Categorical colormap
    s=0.5,
    alpha=0.3
)
ax2.set_title('UMAP Projection Colored by Sex')
ax2.set_xlabel('UMAP Dimension 1')
ax2.set_ylabel('UMAP Dimension 2')
fig.colorbar(plot2, ax=ax2, label='Participant Sex')

plt.show()
